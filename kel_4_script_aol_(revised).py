# -*- coding: utf-8 -*-
"""Kel 4 - Script AOL (Revised).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p0PWopWUUH-AW18cP6xzfhZaxuuYzFSp
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import pyplot as plt
import math

# from google.colab import files
# upload = files.upload()

df = pd.read_csv("D:\Kuliah\Data Mining\AOL_DataMining/heart_statlog_cleveland_hungary_final.csv")
df

df.info()

df.isna().sum()

df = df.drop_duplicates()

categorical_cols = ['sex', 'chest pain type', 'fasting blood sugar',
                    'resting ecg', 'exercise angina', 'ST slope', 'target']

num_cols = 3
num_rows = math.ceil(len(categorical_cols) / num_cols)

fig = plt.figure(figsize=(8*num_cols, 4*num_rows))
grid = plt.GridSpec(num_rows, num_cols, wspace=0.4, hspace=0.6)

df_heart_disease = df[df['target'] == 1]

for i, col in enumerate(categorical_cols):
    if col != 'target':
        ax = fig.add_subplot(grid[i])
        sns.countplot(data=df_heart_disease, x=col, ax=ax)
        ax.set_title(f'Heart Disease Frequency by {col}')
        ax.set_ylabel('Count of Heart Disease (target=1)')
        ax.set_xlabel(col)

plt.tight_layout()
plt.show()

num_col = ['age', 'resting bp s', 'cholesterol', 'max heart rate',
           'oldpeak']

row = 3
col = math.ceil(len(num_col)/ row)

fig = plt.figure(figsize=(8*num_cols, 4*num_rows))
grid = plt.GridSpec(num_rows, num_cols, wspace=0.4, hspace=0.6)

for i, col in enumerate(num_col):
    ax = fig.add_subplot(grid[i])
    sns.histplot(data=df, x=col, ax=ax, kde=True)
    ax.set_title(f'{col} distribution')

plt.tight_layout()
plt.show

num_col = ['age', 'resting bp s', 'cholesterol', 'max heart rate', 'oldpeak']

num_cols = 3
num_rows = math.ceil(len(num_col) / num_cols)

fig = plt.figure(figsize=(8*num_cols, 4*num_rows))
grid = plt.GridSpec(num_rows, num_cols, wspace=0.4, hspace=0.6)

df_heart_disease = df[df['target'] == 1]

for i, col in enumerate(num_col):
    ax = fig.add_subplot(grid[i])
    sns.histplot(data=df_heart_disease, x=col, ax=ax, kde=True)
    ax.set_title(f'{col} Distribution for Heart Disease Cases')
    ax.set_xlabel(col)
    ax.set_ylabel('Count of Heart Disease Cases')

plt.tight_layout()
plt.show()

class_counts = pd.Series({
    '1.0': 508,
    '0.0': 410
})

class_counts.plot(kind='bar', figsize=(8, 6), color=['blue', 'orange'])
plt.xlabel('Target')
plt.ylabel('Count')
plt.title('Count of Each Target Value')
plt.xticks(rotation=0)
plt.show()

def replaceOutliersWithMean(df_removeMean):
    Q1 = df_removeMean.quantile(0.25)
    Q3 = df_removeMean.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    df_replaced = df_removeMean.copy()

    means = df_removeMean.mean()

    for col in df_removeMean.columns:
        is_outlier = (df_removeMean[col] < lower_bound[col]) | (df_removeMean[col] > upper_bound[col])
        df_replaced.loc[is_outlier, col] = means[col]

    return df_replaced

df = replaceOutliersWithMean(df)

# cek imbalance data
class_counts = df['target'].value_counts()
print(class_counts)

# age_range_target_counts = df.groupby(['class_count', 'target']).size().unstack(fill_value=0)

# age_range_target_counts.plot(kind='bar', stacked=True, figsize=(10, 6))
# plt.xlabel('Age Range')
# plt.ylabel('Count')
# plt.title('Distribution of Age Range vs Target')
# plt.legend(title='Target')
# plt.show()
# plt.show()

class_counts = pd.Series({
    '1.0': 508,
    '0.0': 410
})

class_counts.plot(kind='bar', figsize=(8, 6), color=['blue', 'green'])
plt.xlabel('Target')
plt.ylabel('Count')
plt.title('Count of Each Target Value')
plt.xticks(rotation=0)
plt.show()

# sex_target_counts

x = df.drop(columns="target")
y = df['target']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

scaler = MinMaxScaler(feature_range=(0, 1))
smote = SMOTE(random_state=42)

x_resampled, y_resampled = smote.fit_resample(x_train, y_train)

x_resampled = scaler.fit_transform(x_resampled)
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

print(y_resampled.value_counts())

print(y_train.value_counts())

"""Without SMOTE"""

# Decision Tree Without Hyperparameter Tuning (without SMOTE)

dtcWithoutSmote = DecisionTreeClassifier()

dtcWithoutSmote.fit(x_train, y_train)

y_train_pred_withoutSmote = dtcWithoutSmote.predict(x_train)
y_test_pred_withoutSmote = dtcWithoutSmote.predict(x_test)

print("Akurasi Training" , accuracy_score(y_train,y_train_pred_withoutSmote))
print("Akurasi Testing" , accuracy_score(y_test,y_test_pred_withoutSmote))

print("Confusion Matrix: \n", confusion_matrix(y_test, y_test_pred_withoutSmote))

print("Classification Report Testing:\n",classification_report(y_test,y_test_pred_withoutSmote))
ConfusionMatrixDisplay.from_predictions(y_test,y_test_pred_withoutSmote)

# Decision Tree With Hyperparameter Tuning (without SMOTE)

from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 10, 20],
    'min_samples_leaf': [1, 5, 10],
    'criterion': ['gini', 'entropy'],
    'splitter': ['best', 'random'],
}

gsc_withoutSmote = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='accuracy')

gsc_withoutSmote.fit(x_train, y_train)

best_dtc_withoutSmote = gsc_withoutSmote.best_estimator_

best_dtc_withoutSmote.fit(x_train, y_train)

y_pred_best_dtc_train_withoutSmote = best_dtc_withoutSmote.predict(x_train)
y_pred_best_dtc_test_withoutSmote = best_dtc_withoutSmote.predict(x_test)

print("Parameter Terbaik: ", gsc_withoutSmote.best_params_)

print("Akurasi Training: ", accuracy_score(y_train, y_pred_best_dtc_train_withoutSmote))
print("Akurasi Testing: ", accuracy_score(y_test, y_pred_best_dtc_test_withoutSmote))
print("Confusion Matrix:\n ", confusion_matrix(y_test, y_pred_best_dtc_test_withoutSmote))
print("Classification Report Testing:\n", classification_report(y_test, y_pred_best_dtc_test_withoutSmote))
ConfusionMatrixDisplay.from_predictions(y_test,y_pred_best_dtc_test_withoutSmote)

"""With SMOTE"""

# Decision Tree Without Hyperparameter Tuning

dtc = DecisionTreeClassifier()

dtc.fit(x_resampled, y_resampled)

y_train_pred = dtc.predict(x_resampled)
y_test_pred = dtc.predict(x_test)

print("Akurasi Training" , accuracy_score(y_resampled,y_train_pred))
print("Akurasi Testing" , accuracy_score(y_test,y_test_pred))

print("Confusion Matrix:\n ", confusion_matrix(y_test, y_test_pred))

print("Classification Report Testing:\n",classification_report(y_test,y_test_pred))
ConfusionMatrixDisplay.from_predictions(y_test,y_test_pred)

# Decision Tree With Hyperparameter Tuning

from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 10, 20],
    'min_samples_leaf': [1, 5, 10],
    'criterion': ['gini', 'entropy'],
    'splitter': ['best', 'random'],
}

gsc = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='accuracy')

gsc.fit(x_resampled, y_resampled)

best_dtc = gsc.best_estimator_

best_dtc.fit(x_resampled, y_resampled)

y_pred_best_dtc_train = best_dtc.predict(x_resampled)
y_pred_best_dtc_test = best_dtc.predict(x_test)

print("Parameter Terbaik: ", gsc.best_params_)

print("Akurasi Training: ", accuracy_score(y_resampled, y_pred_best_dtc_train))
print("Akurasi Testing: ", accuracy_score(y_test, y_pred_best_dtc_test))
print("Confusion Matrix:\n ", confusion_matrix(y_test, y_pred_best_dtc_test))
print("Classification Report Testing:\n", classification_report(y_test, y_pred_best_dtc_test))
ConfusionMatrixDisplay.from_predictions(y_test,y_pred_best_dtc_test)